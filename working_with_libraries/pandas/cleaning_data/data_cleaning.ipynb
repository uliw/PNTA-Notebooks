{"cells":[{"cell_type":"markdown","id":"ceea997d-f42f-4509-80ec-71c3b62b5be4","metadata":{},"source":["### Data cleaning and processing with pandas.\n\n"]},{"cell_type":"markdown","id":"556b82c8-8231-4500-95dc-08ad293b696f","metadata":{},"source":["#### Always check your files!\n\n"]},{"cell_type":"markdown","id":"1011dfbb-9ffe-4aea-9d58-694ce4581358","metadata":{},"source":["If you execute this code, you will get a lengthy error message, telling you that this file does not exist. \n\n"]},{"cell_type":"code","execution_count":1,"id":"9ec19495-d2fd-4e47-a9b7-caf6044bc768","metadata":{},"outputs":[],"source":["import pandas as pd # inport pandas as pd\ndf :pd.DataFrame = pd.read_csv(\"example_file.csv\") # the pandas dataframe"]},{"cell_type":"markdown","id":"2914884c-d999-49da-b662-ce1aed4268ee","metadata":{},"source":["However, depending on your circumstances you may also get very weird error messages, and a simple typo in the filename can cost you lots of time trying to figure out what is going on. It is thus much better to test yourself  whether a filename exists or not. This is easily done with a few lines of code.\n\n"]},{"cell_type":"code","execution_count":1,"id":"a2d1c530-3bf2-4894-af60-414476ef8123","metadata":{},"outputs":[],"source":["import pathlib as pl \n\nfn: str = \"example_file.csv\"  # file name\ncwd :pl.Path = pl.Path.cwd()  # get the current working directory \nfqfn :pl.Path = pl.Path(f\"{cwd}/{fn}\") # build the fully qualified file name\nif not fqfn.exists():  # check if the file is actually there\n    raise FileNotFoundError(f\"Cannot find file {fqfn}\")"]},{"cell_type":"markdown","id":"6a090473-f452-4735-b619-76ade7015d9b","metadata":{},"source":["I in fact keep a file full of those handy little snippets, so I can use copy/paste whenever I do file operations. The `pathlib` library provides many useful methods to modify the path, the filename, or its extension, but the above will do for this course. In the coming exercises we will often import external data with pandas, so you want to create a second code template where you combine the above with the pandas import statement (you can pass the `fqfn` pathlib object to pandas instead of the filename string) \n\n"]},{"cell_type":"markdown","id":"51114837-65da-4afe-b29a-85e7cdc724c8","metadata":{},"source":["#### Dropping Rows with Missing Values (`NaN`)\n\n"]},{"cell_type":"markdown","id":"6578c2ce-cf32-4e31-8788-a7dc18bc3ce5","metadata":{},"source":["\nWhen working with real-world data, it is common to encounter missing information (i.e., empty cells). Upon reading a data file, pandas places a `NaN` symbol in each cell that is empty. `NaN` stands for \"NotaNumber\". Pandas provides the `dropna()` method, which allows us to filter out rows or columns with missing (`NaN`) values:\n\n"]},{"cell_type":"code","execution_count":1,"id":"9dc79f09-cb1f-4a7f-b88d-ed47172099bb","metadata":{},"outputs":[],"source":["import pandas as pd\n\n# Create a sample DataFrame\ndata = {\n    \"A\": [1, 2, None, 4],\n    \"B\": [None, 2, 3, 4],\n    \"C\": [1, None, 3, 4]\n}\ndf = pd.DataFrame(data)\nprint(\"Original DataFrame:\")\nprint(df)"]},{"cell_type":"code","execution_count":1,"id":"434c793f-de4d-434b-9a19-a23c463f1c01","metadata":{},"outputs":[],"source":["df_cleaned = df.dropna()\n\nprint(\"\\nDataFrame after dropping rows with NaN:\")\nprint(df_cleaned)"]},{"cell_type":"markdown","id":"3defcca5-ab96-492b-9ff7-046fac20b366","metadata":{},"source":["#### Sorting\n\n"]},{"cell_type":"markdown","id":"eda5d290-da94-4aee-9d62-de2ace581017","metadata":{},"source":["\nSorting data by a given column is often the first step in data processing.\nSorting data is useful for identifying trends or ranking entries based on importance. Pandas provides the  `sort_values()` method, which you can use to sort a DataFrame by any column in ascending or descending order. Here’s a generic example:\n\n"]},{"cell_type":"code","execution_count":1,"id":"fda0486c-96be-467f-8539-6f274727562a","metadata":{},"outputs":[],"source":["import pandas as pd\n\n# Create a sample DataFrame\ndata = {\n    \"Name\": [\"A\", \"B\", \"C\", \"D\"],\n    \"Value\": [10, 30, 20, 40]\n}\n\ndf = pd.DataFrame(data)\n\n# Sort the DataFrame by the \"Value\" column in descending order\ndf_sorted = df.sort_values(by=\"Value\", ascending=False)\n\nprint(\"DataFrame sorted by 'Value' in descending order:\")\nprint(df_sorted)"]},{"cell_type":"markdown","id":"cd37f057-e5cc-426f-83e0-8db44da3dbcb","metadata":{},"source":["#### Grouping and subtotals\n\n"]},{"cell_type":"markdown","id":"dea6e76d-ccf4-4063-ab9c-e9439a269099","metadata":{},"source":["\nGrouping is a powerful feature in pandas that allows you to split a DataFrame into groups based on the values in one or more columns. After grouping, you can apply aggregate functions (e.g., sum, mean, or count) to calculate useful summary statistics for each group. This is similar to the pivot table feature in excel.\n\n"]},{"cell_type":"code","execution_count":1,"id":"70f229f0-ddce-4954-b1d4-4d4bff01e568","metadata":{},"outputs":[],"source":["# Grouping data and calculating totals:\nimport pandas as pd\n\n# Create a sample DataFrame\ndata = {\n    \"Category\": [\"A\", \"B\", \"A\", \"C\", \"B\", \"A\"],\n    \"Value\": [10, 20, 30, 40, 50, 60]\n}\n\ndf = pd.DataFrame(data)\n\n# Group by the \"Category\" column and calculate the total (sum) for each group\ngrouped_totals = df.groupby(\"Category\")[\"Value\"].sum()\nprint(grouped_totals)"]},{"cell_type":"markdown","id":"ad688803-07a8-4db2-aad2-fbcfa2e74a78","metadata":{},"source":["#### Creating a data pipeline\n\n"]},{"cell_type":"markdown","id":"4ef61792-d517-474d-a8b0-7cec2a345e8f","metadata":{},"source":["\nIn the above examples we used a variety of steps, to pre-process our data. Depending on your data, this can get quite messy. Sometimes it is thus useful to define explicit functions to do the data processing, and then join them together in a clean and readable way. Whether this step is worth it depends on the complexity of your task.\n\n"]},{"cell_type":"code","execution_count":1,"id":"02c9f995-2bb6-4fe7-b382-75c4e6b676d7","metadata":{},"outputs":[],"source":["import pandas as pd\n\n# Sample data\ndata = {\n    'Category': ['A', 'B', 'A', 'B', 'C', 'C', 'A', 'B'],\n    'Values': [10, 20, None, 40, 30, None, 50, 60]\n}\n\ndf = pd.DataFrame(data)\n\n# Define functions for each step\ndef drop_missing(df):\n    return df.dropna()\n\ndef group_and_sum(df):\n    return df.groupby('Category', as_index=False).sum()\n\ndef sort_by_values(df):\n    return df.sort_values(by='Values', ascending=False)\n\n# Use the pipe method to transform the data\ncleaned_df = (df\n              .pipe(drop_missing)\n              .pipe(group_and_sum)\n              .pipe(sort_by_values))\n\nprint(cleaned_df)"]},{"cell_type":"markdown","id":"908700fc-d97d-4a0c-b53a-abd801421a22","metadata":{},"source":["#### Pandas and Date-Time Data\n\n"]},{"cell_type":"markdown","id":"08f503d9-430a-4745-ae21-78893a24784d","metadata":{},"source":["Sometimes we need to work with date-time data, like `2023-01-01 12:00:00` but many data processing tools work better with numbers instead of dates. A common way to represent dates as numbers is to use **Unix timestamps**.\n\n"]},{"cell_type":"markdown","id":"13157017-0b6c-42af-a840-5b7b0984b8b6","metadata":{},"source":["##### What is a Unix Timestamp?\n\n"]},{"cell_type":"markdown","id":"eae29a46-de21-4fdb-8998-7d76d73fd990","metadata":{},"source":["A Unix timestamp is a numeric value that represents the number of ****seconds**** since January 1, 1970 (commonly called the \"epoch time\"). Example:\n\n    - 1970-01-01 00:00:00 UTC → 0\n    - 1970-01-01 00:00:01 UTC → 1\n    - 2023-01-01 12:00:00 UTC → 1672574400\n\nBy converting date-time data into Unix timestamps, we can efficiently store, compare, and work with time in numeric form.\n\n"]},{"cell_type":"markdown","id":"655872fa-9785-4b14-93a7-62e93de1aff2","metadata":{},"source":["##### How to Import and Convert Date-Time Data\n\n"]},{"cell_type":"markdown","id":"75951c94-fe63-40ee-89d8-a17ae418f12b","metadata":{},"source":["Assume you have a CSV file (`data.csv`) that looks like this:\n\n    | datetime_column       | value |\n    |-----------------------|-------|\n    | 2023-01-01 12:00:00  |   100 |\n    | 2023-01-02 13:30:00  |   200 |\n    | 2023-01-03 15:45:00  |   300 |\n\nHere’s how to:\n\n1.  Read in the file.\n2.  Convert the date-time information into Unix timestamps.\n\n"]},{"cell_type":"code","execution_count":1,"id":"ef50c2dd-86ec-49fd-8a2e-9a174ec0195b","metadata":{},"outputs":[],"source":["import pandas as pd\n\n# Step 1: Load the CSV file into a pandas DataFrame\ndf = pd.read_csv('data.csv')\n\n# Step 2: Convert the date-time column into pandas' datetime format\ndf['datetime_column'] = pd.to_datetime(df['datetime_column'])\n\n# Step 3: Convert the datetime column to Unix timestamps in seconds\ndf['timestamp'] = df['datetime_column'].astype('int64') // 10**9\n\n# Step 4: Print the updated DataFrame to see the result\nprint(df)"]},{"cell_type":"markdown","id":"ae7ca2a2-d854-433e-820e-6c29fdc72052","metadata":{},"source":["##### How the Code Works\n\n"]},{"cell_type":"markdown","id":"e99e37bf-0cfb-4638-84e5-ecc28c701534","metadata":{},"source":["The `pd.to_datetime()` function transforms the dates and times in `datetime_column` into a special format that pandas understands. This makes it easy to manipulate and extract time-related information.\n\nThe `.astype('int64')` converts the datetime column into a numeric value representing the number of **nanoseconds** since 1970-01-01.  Why nanoseconds? Pandas stores dates with very high precision!  \n\nTo get seconds we divide by `1e9` (10<sup>9</sup>), because there are 1 billion nanoseconds in one second. Note the use of `//` instead of `/`.  The `//` operator  will perform an integer division (cast to the nearest lower integer), ensuring you always get an integer result.\n\nAfter running the code, the DataFrame will look like this:\n\n    | datetime_column       | value | timestamp |\n    |-----------------------+-------+----------------|\n    | 2023-01-01 12:00:00  |   100 |      1672574400 |\n    | 2023-01-02 13:30:00  |   200 |      1672666200 |\n    | 2023-01-03 15:45:00  |   300 |      1672759500 |\n\n-   The `datetime_column` shows the original date-time.\n-   The `value` column contains your other data.\n-   The `timestamp` column now contains the numeric representation of the datetime in ****seconds**** since 1970-01-01.\n\n"]},{"cell_type":"markdown","id":"8849e808-4779-4d69-82ce-46314d8d1ef5","metadata":{},"source":["#### Categorizing Date time data\n\n"]},{"cell_type":"markdown","id":"0b21bf8b-9187-4fe7-9263-5225a4c75f3c","metadata":{},"source":["To categorize your date-time data in a pandas DataFrame into `day` and `night`, you can use the `dt` accessor to extract the hour from the `datetime` column. You can then define a function or use a lambda function with conditions to label each row as `day` or `night` based on the hour. Here's how you can do this:\n\n"]},{"cell_type":"code","execution_count":1,"id":"56902a63-4fd1-4113-91bc-9b164b3199c5","metadata":{},"outputs":[],"source":["import pandas as pd\n\n# Example data (datetime data for several days)\ndata = {\n    'datetime': [\n        '2023-10-01 01:00:00',\n        '2023-10-01 13:00:00',\n        '2023-10-01 23:00:00',\n        '2023-10-02 09:00:00',\n        '2023-10-02 20:00:00',\n    ],\n    'value': [10, 20, 15, 25, 30]\n}\n\n# Create a pandas DataFrame\ndf = pd.DataFrame(data)\n\n# Convert the =datetime= column to pandas datetime format\ndf['datetime'] = pd.to_datetime(df['datetime'])\n\n# Define the time categorization\n# Assume 'night' is from 20:00 (8 PM) to 5:59 (5:59 AM), and the rest is 'day'.\ndef categorize_time(hour):\n    if 6 <= hour < 20:  # 6 AM to 7:59 PM are day\n        return 'day'\n    else:               # 8 PM to 5:59 AM are night\n        return 'night'\n\n# Apply the categorization function to the DataFrame\ndf['time_category'] = df['datetime'].dt.hour.apply(categorize_time)\n\n# Output the resulting DataFrame\nprint(df)"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":5}