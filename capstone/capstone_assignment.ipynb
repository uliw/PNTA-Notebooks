{"cells":[{"cell_type":"markdown","metadata":{},"source":"Capstone Assignment\n===================\n\n**Author:** Ulrich G Wortmann\n\n"},{"cell_type":"markdown","metadata":{},"source":["## Goal\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Today's assignment has two parts:\n\n1.  Write a program (notebook) that can do regression analysis on arbitrary CSV-files. You can re-use many parts of last week's assignment, but you likely have to modify it. The user of your program will only specify the file name, the column index of the independent variable, the column index of the dependent variable, and whether any of these require a log transform. Your code will produce a histogram plot, a fully annotated regression plot including the residuals. The plot must use the CSV-file column headers as axis-labels\n2.  Use the new code to solve the calibration assignment below, i.e., you submit a notebook with your code and the results obtained with the calibration data below.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Preparing the code\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In the following, we want to create a notebook that can be used with any given dataset to produce a linear regression analysis. The point of the notebook is to make this analysis as comfortable as possible, so we will add a few bells and whistles. The notebook should have the following sequence of cells:\n\n1.  A cell with all import statements, variable definitions for the file name, the index values for the columns you want to analyze,  the graph labels, the name of the figure file (e.g., xyz-lin-reg.pdf pr png etc.), and whether this analysis will use a log transformation or not. Use the following variable names:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# data file\nfn: str = \"foo.csv\"  # replace foo with your file name\nfig_fn: str = \"foo.pdf\"  # figure file name\n\n# select data from csv file\nx_col: int = 1  # independent_var\ny_col: int = 0  # dependent_var\nlog_transform: str = \"\"  # use as \"X\", or \"Y\" or \"XY\"\nsig: float = 0.05  # = 1 - sig > 0.95 = 95% significance"]},{"cell_type":"markdown","metadata":{},"source":["Notes: If you do a log transform, your code should change the respective figure captions to (log(&#x2026;)). \n\n2.  Starting with this cell, all code actions should only depend on the variables defined in the first cell. Continue with reading the data from the CSV file, and mapping the data frame columns to generic variables (e.g., `X` and `Y`, see below). Add a statement to sort the data frame in ascending order by \"X\".\n3.  Plot \"X\" and \"Y\" as histograms to get a visual test if the data is normal distributed.\n4.  Print the Pearson correlation coefficient using a suitable print statement (i.e., don't just print a number!)\n5.  Perform the regression analysis for `Y~X` and print the resulting parameters\n6.  Extract all data needed to make a regression plot that shows the regression parameters, and the confidence intervals for the model and the predictions. In addition, also extract the residuals from the results object like this:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["residuals: pd.Series = results.resid"]},{"cell_type":"markdown","metadata":{},"source":["7.  Create a graph with 1 column and two rows. The first plot will be the usual regression plot, whereas the second graph should plot the residuals versus the x-axis data. The graph should be 120 dpi, 6 by 8 inches. See this example:\n\n![img](./sed.png)\n\n8.  Note that you should derive the text position for the regression parameters automatically. You can retrieve the axis dimensions as `ax.get_xlim()`  and `ax.get_ylim()`.  Consider whether your correlation coefficient is positive or negative when you compute the text position.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Mapping the column names\n\n"]},{"cell_type":"markdown","metadata":{},"source":["To keep our code universal, and to avoid potential problems with the statsmodel library, it is best if we rename the columns used in the statistical model. So first extract the column headers for the independent and dependent variables, and assign their names to some variables (also to be used in the plotting step). Using these variables \nwe can replace the existing column headers in the data frame with our generic names (i.e., \"X\" and \"Y\"). We achieve this by passing a dictionary that defines the mapping to the `df.rename()` method. Note that `independent_var` and  `dependent_va` are string variables that contain the names of the respective column headers.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# replace df column names\nmap_headers: dict[str:str] = {independent_var: \"X\",\n                              dependent_var: \"Y\"}\n\ndf.rename(map_headers, axis='columns', inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Rules\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   At this point, you have seen many examples of well-written code. Follow these examples in building your own code\n    -   Provide a header with an authorship and purpose statement\n    -   When reading the CSV file, use the pathlib library to ensure that the file exists\n    -   Use comments\n    -   Use type hints\n    -   If you want to, use functions, but for this exercise, it is not needed\n    -   All figures use the ggplot style\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Testing your code\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Run the notebook with the storks and sulfate reduction data, to make\nsure it functions as intended. Note: I do not need to see these\ntests. This is purely for your benefit.\n\nPay attention to the residuals plot. For well-behaved data, the residuals should be evenly distributed, if they are not (e.g., in the stork data), or they show a clear pattern, it is a strong indication that your analysis is not valid.  You can test this with the sedimentation versus sulfate reduction data set.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Let's put your code to use\n\n"]},{"cell_type":"markdown","metadata":{},"source":["As part of my research in the International Ocean Drilling Program\n(IODP), I occasionally go on expeditions with the JR Joides Resolution\n\n![img](Joides.jpg)\n\nThe ship takes about 28 scientists, 28 technicians, 28 drillers, and\nabout 28 seamen. Expeditions are typically two months in length. While\nthe scientists typically have cruise-related research objectives,\ntheir duties during the cruise are taken up by routine measurements\ndescribing the core materials. This includes geomagnetic,\nsedimentological, chemical, biological, mineralogical, and structural\ndata.\n\nI participated twice and was part of the team documenting the\ninorganic chemistry of the water that is trapped between sediment\ngrains - the so-called interstitial water (IW).\n\nThe chemistry of the interstitial water is monitored for many ionic\nspecies, among them Ammonium (NH<sub>4</sub><sup>+</sup>). Ammonium is measured on a\nphotospectrometer, which measures how much light passes through a\nsample container at a specified wavelength. This allows for exact concentration measurements but requires manual calibration. In\nthe first step, you have to mix standards. In the second step, you\nmeasure those standards to create a calibration function. The\ncalibration function allows you to relate the light absorbance to the\nNH<sub>4</sub><sup>+</sup> concentration. In other words, we build a linear model to predict\nthe NH<sub>4</sub><sup>+</sup> concentrations based on the absorbance values we get\nfrom the photospectrometer.  The whole process is a bit of an art, but\nafter practicing it for three days, I got this:\n\n![img](ammonium_311.png)\n\nBelow, you will find calibration data for my first expedition in 1998. I\nwas a total noob, I did not practice, and likely I was not careful\nenough when I prepared my calibration standards. Alas, my lab journal lacks enough detail to understand why it was so bad.\n\nThe data for the above table is in the file `ammonia-1998.csv`. \nNext use your shiny new code to perform a regression analysis where you treat the absorbance data as\nthe independent variable and the NH<sub>4</sub><sup>+</sup> concentration as the dependent\nvariable. The regression analysis should be performed at the 99% confidence level, and there is no need for a log transform.\n\nDescribe in words the measurement (i.e., prediction) uncertainty for NH<sub>4</sub><sup>+</sup> in units umol/l  for an absorbance reading of 600. Write a few words about how this compares to the uncertainty you get for `ammonia-2005.csv` .\n\nNote the structure in the residuals for the 2005 data. This strongly\nsuggests that a liner model is not suitable for this data and that the\nmeasurement error could be further reduced by a polynomial fit.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Marking Scheme\n\n"]},{"cell_type":"markdown","metadata":{},"source":["There are no partial points. Total Points: 24 pts\n\n-   Correct use of type hints: 1 pts\n-   Correct use of comments and doc strings 1pt\n-   Correct results for r<sup>2</sup>, p, and the regression equation: 3 pts\n-   Correct graph labels: 1 pt\n-   Display of the confidence interval for the regression model: 1 pt\n-   Display of the confidence interval for the predictions of the\n    model: 1 pt\n-   Correct value for the measurement uncertainty 6 pts\n-   Code calculates useful values for the regression text coordinates 2 pts\n-   Code correctly replaces column headers 2 pts\n-   Code handles log-transforms specified in `log_transform` variable 2pts\n-   Code adjusts axis-labels depending on `log_transform` variable 2 pts\n-   Code plots the file name as plot title 1 pt\n-   Correct graph dimensions 1 pt\n-   **Included your CSV data with your submission!** Otherwise, the TA will use his own data file, and you will lose the 6 points for the measurement uncertainty.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Submission Instructions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Create a new (or copy and existing) notebook in your `submissions`\nfolder before editing it. Otherwise, your edits may be overwritten the\nnext time you log into syzygy. Please name your copy\n\"Assignment-Name-FirstName-LastName\": \n\n-   Replace the `Assignment-Name` with the name of the assignment\n    (i.e., the filename of the respective Jupyter Notebook)\n-   `FirstName-Last-Name` with your own name.\n\nNote: If the notebook contains images, you must also copy the image files!\n\nYour notebook/pdf must start with the following lines \n\n**Assignment Title**\n\n**Date:**\n\n**First Name:**\n\n**Last Name:**\n\n**Student: Id**\n\nBefore submitting your assignment:\n\n-   Check the marking scheme and ensure you have covered all requirements.\n-   re-read the learning outcomes and verify that you are comfortable\n    with each concept. If not, please speak up on the discussion board\n    and ask for further clarification. I can guarantee that if you feel\n    uncertain about a concept, at least half the class will be in the\n    same boat. So don't be shy!\n\nTo submit your assignment, you need to download it as `ipynb` notebook\nformat **and** `pdf` format. The best way to export your notebook as pdf\nis to use your browser's print function (`Ctrl-P`) and then select\n`Save as pfd`.  Please submit both files on Quercus. Note that the pdf\nexport can fail if your file contains invalid markup/python code. So\nyou need to check that the pdf export is complete and does not miss\nany sections. If you have export problems, don't hesitate to contact\nthe course instructor directly.\n\nNotebooks typically have empty code cells in which you must enter\npython code. Please use the respective cell below each question, or\ncreate a python cell where necessary. Add text cells to enter your\nanswers where appropriate. Your responses will only count if the code\nexecutes without error. It is thus recommended to run your solutions\nbefore submitting the assignment.\n\n**Note: Unless specifically requested, do not type your answers by**\n**hand. Instead, write code that produces the answer. Your pdf file**\n**should show the code and the results of the code execution.**\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}